{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MATH 693A Advanced Numerical Methods: Computational Optimization HW 3\n",
    "### By Will McGrath"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1\n",
    "### Write a Program that implements the dogleg method. Choose $B_k$ to be the exact Hessian. Apply it to solve Rosenbrockâ€™s function: $f(x) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$. \n",
    "### Use an initial trust region radius of 1. Set maximum trust region radius to 300. Use the initial point: $x_0 = [-1.2, 1]$ and then try another point $x_0 = [2.8, 4]$. Do the following for each of the initial points."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here are the parameters you should use for the Dogleg Algorithm:\n",
    "### a. Use $|| \\nabla{f(x_k)} || < 10^{-8}$ as the stopping criteria for your optimization algorithm.\n",
    "### b. State the total number of iterations obtained in your optimization algorithm.\n",
    "### c. Plot the objective function $f(x)$. On the same figure, plot the $x_k$ values at the different iterates of your optimization algorithm.\n",
    "### d. Plot the size of the objective function as a function of the iteration number. Use semi-log plot.\n",
    "### e. You should hand in (i) your code (ii) the first 4 and last 4 values of $x_k$ obtained from your program.\n",
    "### f. Determine the minimizer of the Rosenbrock function $x^*$.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 2\n",
    "### Experiment with the update rule for the trust region by changing the constants in Algorithm 4.1 in the text Numerical Optimization by Nocedal and Wright 2006. State what you experimented with and discuss your observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def jumpingOnClouds(c):\n",
    "    # Write your code here\n",
    "    num_of_jumps = 0\n",
    "    indx = 0\n",
    "    while indx < len(c)-1:\n",
    "        if indx+2 < len(c) and c[indx+2] == 0:\n",
    "            indx += 2\n",
    "            num_of_jumps +=1\n",
    "\n",
    "        else:\n",
    "            indx += 1\n",
    "            num_of_jumps += 1\n",
    "\n",
    "    return num_of_jumps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "c = [0,0,1,0,0,0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
    "#c = [0,0]\n",
    "jumpingOnClouds(c)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "fcc29b29288bfae7cd1f9163060093e50b801b38050887fcfbbbb4f16f6170ab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}