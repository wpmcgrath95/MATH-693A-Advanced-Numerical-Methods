{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MATH 693A Advanced Numerical Methods: Computational Optimization HW 3\n",
    "### By Will McGrath"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1\n",
    "### Write a Program that implements the dogleg method. Choose $B_k$ to be the exact Hessian. Apply it to solve Rosenbrock’s function: $f(x) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$. \n",
    "### Use an initial trust region radius of 1. Set maximum trust region radius to 300. Use the initial point: $x_0 = [-1.2, 1]$ and then try another point $x_0 = [2.8, 4]$. Do the following for each of the initial points."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Here are the parameters you should use for the Dogleg Algorithm:\n",
    "### a. Use $\\| \\nabla{f(x_k)} \\|< 10^{-8}$ as the stopping criteria for your optimization algorithm.\n",
    "### b. State the total number of iterations obtained in your optimization algorithm.\n",
    "### c. Plot the objective function $f(x)$. On the same figure, plot the $x_k$ values at the different iterates of your optimization algorithm.\n",
    "### d. Plot the size of the objective function as a function of the iteration number. Use semi-log plot.\n",
    "### e. You should hand in (i) your code (ii) the first 4 and last 4 values of $x_k$ obtained from your program.\n",
    "### f. Determine the minimizer of the Rosenbrock function $x^*$.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trust-region method uses a quadratic model. At each iteration, the step is calculated by solving the following quadratic problem (sub-problem) using dogleg method:\n",
    "> Note: radius increases only if $|p_k|$ reaches the trust-region border\n",
    "- $\\bar{p_k} = \\argmin_{\\| \\bar{p} \\| \\le \\Delta{_k}}[f(\\bar{x_k}) + \\bar{p}^T\\nabla{f(\\bar{x_k})} + \\frac{1}{2}\\bar{p}^TB_k\\bar{p}]$\n",
    "    - When the first three terms of the quadratic model agrees with the Taylor expansion: S.T. $B_k = \\nabla^2f(\\bar{x_k})$, the algorithm is called the trust-region Newton Method. The locally constrained trust region problem is to minimize model $m_k$ whhich is based on the Taylor expansion of the objective $f$ at the current point(where $T_k$ is the trust region and $\\bar{p_k}$ is now $\\bar{p}$ since $\\bar{m_k}$ is being iterated):\n",
    "- $ \\bar{p_k} = \\min_{\\bar{p} \\in T_k} m_k(\\bar{p}) = \\min_{\\bar{p} \\in T_k} [f(\\bar{x_k}) + \\bar{p}^T\\nabla{f(\\bar{x_k})} + \\frac{1}{2}\\bar{p}^TB_k\\bar{p}]$. The full step is the unconstrained minimum of the quadratic model: \n",
    "- $\\bar{p_k}^{FS} = -B_k^{-1}\\nabla{f(\\bar{x_k})}$. The step in the steepest descent direction is given by the unconstrained minimum of the quadratic model along the steepest descent direction:\n",
    "- $\\bar{p_k}^{U} = - \\frac{\\nabla{f(\\bar{x_k})}^T\\nabla{f(\\bar{x_k})}}  {\\nabla{f(\\bar{x_k})}^T B_k \\nabla{f(\\bar{x_k})}} \\nabla{f(\\bar{x_k})}$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Rosenbrock function\n",
    "def objective_func(xbar_k):\n",
    "    x = xbar_k[0]\n",
    "    y = xbar_k[1]\n",
    "\n",
    "    return 100*(y - x**2)**2 + (1 - x)**2\n",
    "\n",
    "def gradient(xbar_k):\n",
    "    x = xbar_k[0]\n",
    "    y = xbar_k[1]\n",
    "\n",
    "    return np.array([400*x**3 - 400*x*y + 2*x - 2, 200*(y - x**2)])\n",
    "\n",
    "def hessian(xbar_k):\n",
    "    x = xbar_k[0]\n",
    "    y = xbar_k[1]\n",
    "    \n",
    "    return np.array([[1200*x**2 - 400*y + 2, -400*x],[-400*x, 200]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part a, b, e, f"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dogleg Method:\n",
    "- Quadratic equation $\\vert\\vert \\bar{p_k}^U + (\\tau^* - 1)(\\bar{p_k}^{FS}  - \\bar{p_k}^U) \\vert\\vert^2 = \\Delta_k^2$ where $\\tau^* \\in [1,2]$ and solve for $\\tau$ (only 1 positive root)\n",
    "- Solving for the $\\tau^*$ using the quadratic formula gives $\\tau^* = \\frac{\\Delta_k \\ - \\ \\bar{p_k}^U}{\\bar{p_k}^{FS} \\ - \\ \\bar{p_k}^U} - 1$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def dogleg_method(xbar_k, grad, Hk, Bk, trust_region):\n",
    "    # compute the Newton point - this is the optimum for the quadratic model function\n",
    "    # if it's inside the trust radius then return this point\n",
    "    # test if the full step is within the trust region\n",
    "    \n",
    "    # compute the Cauchy point - this is the predicted optimum along the direction of steepest descent\n",
    "    # if Cauchy point is outside the trust region, then return the point where the path intersects the boundary\n",
    "    U_num = -np.dot(grad(xbar_k), grad(xbar_k))\n",
    "    U_den = np.dot(grad(xbar_k), np.dot(Bk, grad(xbar_k)))\n",
    "    pbar_U_k = (U_num / U_den) * grad(xbar_k) # Cauchy point\n",
    "    pbar_FS_k = -np.dot(Hk, grad(xbar_k)) # Newton point\n",
    "    \n",
    "    if np.linalg.norm(pbar_U_k) >= trust_region:\n",
    "        pbar_DL_k = trust_region * pbar_U_k / np.linalg.norm(pbar_U_k) # where pbar_DL_k = dogleg pbar  \n",
    "\n",
    "    elif np.linalg.norm(pbar_FS_k) <= trust_region: \n",
    "        pbar_DL_k = pbar_FS_k\n",
    "\n",
    "    else:\n",
    "        # find the solution to the scalar quadratic equation and compute the intersection of the trust region boundary\n",
    "        # then line segment connecting the Cauchy and Newton points\n",
    "        # this requires solving a quadratic equation\n",
    "        # solve the quadratic equation for positive time t using the quadratic formula\n",
    "        # tau_star = ((trust_region - pbar_U_k) / (pbar_FS_k - pbar_U_k)) + 1\n",
    "        \n",
    "        diff_FS_U_k = pbar_FS_k - pbar_U_k\n",
    "        dot_pbar_U_k = np.dot(pbar_U_k, pbar_U_k)\n",
    "\n",
    "        dot_diff_FS_U_k = np.dot(diff_FS_U_k, diff_FS_U_k)\n",
    "        dot_U_diff_FS_U_k = np.dot(pbar_U_k, diff_FS_U_k)\n",
    "        \n",
    "        factor = dot_U_diff_FS_U_k**2 - dot_diff_FS_U_k * (dot_pbar_U_k - trust_region**2)\n",
    "        tau_star = ((np.sqrt(factor) - dot_U_diff_FS_U_k) / dot_diff_FS_U_k ) + 1\n",
    "\n",
    "        # decide on which part of the trajectory to take\n",
    "        pbar_DL_k = pbar_U_k + (tau_star - 1) * (pbar_FS_k - pbar_U_k)\n",
    "\n",
    "    return pbar_DL_k"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trust Region: \n",
    "- Set $k = 1, \\hat{\\Delta} > 0, \\Delta_0 \\in (0, \\hat{\\Delta}),$ and $\\eta \\in (0, \\frac{1}{4})$ S.T. $\\hat{\\Delta}$ = max trust region radius, and $\\Delta_0$ = initial trust region radius\n",
    "- Given a step $\\bar{p_k}$ we define the ratio: $\\rho_k=\\frac{actual \\ reduction}{predicted \\ reduction} = \\frac{f(\\bar{x_k}) \\ - \\ f(\\bar{x_k} + \\bar{p_k})}{m_k(0) \\ - \\ m_k(\\bar{p_k})}$\n",
    "- If $\\rho_k < 0$ We shrink the size of the trust region.\n",
    "- If $\\rho_k ≈ 0$ Then we shrink the size of the trust region.\n",
    "- If $\\rho_k ≈ 1$ Then the model is in good agreement with the objective; in this case it is (probably) safe to expand the trust region for the next iteration.\n",
    "- Else we keep the size of the trust region."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trust region algorithm \n",
    "def trust_reg_dogleg(x0, obj_func, grad, hess, grad_stop_criteria, eta=0.15, initial_trust_radius=1, max_trust_radius=300):\n",
    "    xbar_k = x0 # xbar_k = xbar_transposed\n",
    "    trust_reg = initial_trust_radius\n",
    "    k = 1\n",
    "    k_list, xbar_list, obj_func_xbar_list, pbar_list, rho_list, trust_reg_list = [], [], [], [], [], []\n",
    "\n",
    "    while np.linalg.norm(grad(xbar_k)) > grad_stop_criteria:\n",
    "        Bk = hess(xbar_k)\n",
    "        Hk = np.linalg.inv(Bk) # hessian of Bk inverse\n",
    "\n",
    "        # get approx. step pbar_k by dogleg method (gives minimized pbar_k)\n",
    "        pbar_k = dogleg_method(xbar_k, grad, Hk, Bk, trust_reg)\n",
    "\n",
    "        # define a ratio measuring the success of a step\n",
    "        # given a step pbar_k we define the ratio: rho_k = actual reduction / predicted reduction \n",
    "        mk_0 = obj_func(xbar_k)\n",
    "        mk_pbar_k = obj_func(xbar_k) + np.dot(grad(xbar_k),  pbar_k) + 0.5 * np.dot(pbar_k, np.dot(Bk, pbar_k))\n",
    "        act_reduc = obj_func(xbar_k) - obj_func(xbar_k + pbar_k)\n",
    "        pred_reduc = mk_0 - mk_pbar_k\n",
    "        rho_k = act_reduc / pred_reduc\n",
    "\n",
    "        # rho is close to zero or negative, therefore the trust region must shrink\n",
    "        if rho_k < 0.25:\n",
    "            trust_reg = 0.25 * trust_reg\n",
    "\n",
    "        # rho is close to one and pbar_k has reached the boundary of the trust region, therefore the trust region must be expanded\n",
    "        # euclidean norm of pbar_k = sqrt(np.dot(pbar_k, pbar_k)) = np.linalg.norm(pbar_k)\n",
    "        else:\n",
    "            if rho_k > 0.75 and np.linalg.norm(pbar_k) == trust_reg:\n",
    "                trust_reg = min(2 * trust_reg, max_trust_radius)\n",
    "            else:\n",
    "                trust_reg = trust_reg\n",
    "        \n",
    "        # add to dataframe\n",
    "        if k == 1:\n",
    "            xbar_list.append(x0)\n",
    "            k_list.append(0)\n",
    "            obj_func_xbar_list.append(obj_func(x0))\n",
    "            pbar_list.append(np.nan)\n",
    "            rho_list.append(np.nan)\n",
    "            trust_reg_list.append(np.nan)\n",
    "\n",
    "        # choose position for the next iteration\n",
    "        if rho_k > eta:\n",
    "            xbar_k = xbar_k + pbar_k\n",
    "        else:\n",
    "            xbar_k = xbar_k\n",
    "        \n",
    "        xbar_list.append(xbar_k)\n",
    "        k_list.append(k)\n",
    "        obj_func_xbar_list.append(obj_func(xbar_k))\n",
    "        pbar_list.append(pbar_k)\n",
    "        rho_list.append(rho_k)\n",
    "        trust_reg_list.append(trust_reg)\n",
    "\n",
    "        k = k + 1\n",
    "\n",
    "        trust_reg_dogleg_df = pd.DataFrame(\n",
    "        [[k_list, xbar_list, obj_func_xbar_list, pbar_list, rho_list, trust_reg_list]], \n",
    "        columns=['iteration', 'xbar', 'f(xbar)', 'pbar', 'rho', 'trust_region']\n",
    "    ).explode(['iteration', 'xbar', 'f(xbar)', 'pbar', 'rho', 'trust_region']).reset_index(drop=True)\n",
    "\n",
    "    return trust_reg_dogleg_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trust_reg_dogleg_df_1 = trust_reg_dogleg([-1.2, 1], objective_func, gradient, hessian, 10**(-8))\n",
    "trust_reg_dogleg_df_1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Initial point: {trust_reg_dogleg_df_1['xbar'].iloc[0]}\")\n",
    "print(f\"Minimizer using trust region dogleg method (x*): {trust_reg_dogleg_df_1['xbar'].iloc[-1]}\")\n",
    "print(f\"Value of function at xbar: {objective_func(trust_reg_dogleg_df_1['xbar'].iloc[0])}\")\n",
    "print(f\"Value of function at x*: {objective_func(trust_reg_dogleg_df_1['xbar'].iloc[-1])}\")\n",
    "print(f\"Number of iterations: {len(trust_reg_dogleg_df_1['iteration']) - 1}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trust_reg_dogleg_df_2 = trust_reg_dogleg([2.8, 4], objective_func, gradient, hessian, 10**(-8))\n",
    "trust_reg_dogleg_df_2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Initial point: {trust_reg_dogleg_df_2['xbar'].iloc[0]}\")\n",
    "print(f\"Minimizer using trust region dogleg method (x*): {trust_reg_dogleg_df_2['xbar'].iloc[-1]}\")\n",
    "print(f\"Value of function at xbar: {objective_func(trust_reg_dogleg_df_2['xbar'].iloc[0])}\")\n",
    "print(f\"Value of function at x*: {objective_func(trust_reg_dogleg_df_2['xbar'].iloc[-1])}\")\n",
    "print(f\"Number of iterations: {len(trust_reg_dogleg_df_2['iteration']) - 1}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part c"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def contourplot(objective_func, x_range, y_range, title, ncontours=500):\n",
    "    xmin = x_range[0]\n",
    "    xmax = x_range[1]\n",
    "    ymin = y_range[0]\n",
    "    ymax = y_range[1]\n",
    "\n",
    "    # range of x and y \n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    y = np.linspace(ymin, ymax, 100)\n",
    "    X, Y = np.meshgrid(x,y)\n",
    "    xbar = [X,Y]\n",
    "    Z = objective_func(xbar)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.contour(X, Y, Z, ncontours, cmap = 'hsv'); # plot the contours\n",
    "    plt.scatter(1, 1, marker=\"x\", s=150, color=\"black\", label = 'Minimum');  # mark the minimum\n",
    "    plt.legend(loc=0)\n",
    "    plt.title(\"Minimize $f(x,y)=100(y-x^2)^2 + (1-x)^2$ with %s\"%title);\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot objective function\n",
    "contourplot(objective_func, [-1.4, 1.4], [-0.3, 1.3], \"x0 = [-1.2, 1] Using Trust Regions\")\n",
    "\n",
    "# plot random iterations\n",
    "xbar_list_1 = trust_reg_dogleg_df_1['xbar'].to_list()\n",
    "pt1 = xbar_list_1[0]\n",
    "pt2 = xbar_list_1[5]\n",
    "pt3 = xbar_list_1[10]\n",
    "pt4 = xbar_list_1[15]\n",
    "pt5 = xbar_list_1[20]\n",
    "pt6 = xbar_list_1[25]\n",
    "all_pts = [pt1, pt2, pt3, pt4, pt5, pt6]\n",
    "\n",
    "for pt in all_pts:\n",
    "    plt.scatter(pt[0], pt[1], marker='o', s=10, color='black');\n",
    "\n",
    "for i in range(1, len(all_pts)):\n",
    "    plt.plot((all_pts[i-1][0], all_pts[i][0]), (all_pts[i-1][1], all_pts[i][1]), color='black');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot objective function\n",
    "contourplot(objective_func, [-1.3, 3.1], [-0.4, 4.5], \"x0 = [2.8, 4] Using Trust Regions\")\n",
    "\n",
    "# plot random iterations\n",
    "xbar_list_2 = trust_reg_dogleg_df_2['xbar'].to_list()\n",
    "pt1 = xbar_list_2[0]\n",
    "pt2 = xbar_list_2[5]\n",
    "pt3 = xbar_list_2[10]\n",
    "pt4 = xbar_list_2[15]\n",
    "pt5 = xbar_list_2[20]\n",
    "pt6 = xbar_list_2[23]\n",
    "all_pts = [pt1, pt2, pt3, pt4, pt5, pt6]\n",
    "\n",
    "for pt in all_pts:\n",
    "    plt.scatter(pt[0], pt[1], marker='o', s=10, color='black');\n",
    "\n",
    "for i in range(1, len(all_pts)):\n",
    "    plt.plot((all_pts[i-1][0], all_pts[i][0]), (all_pts[i-1][1], all_pts[i][1]), color='black');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part d"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# semi-log plots\n",
    "def plot_semilogy(xbar_list_1, xbar_list_2):\n",
    "    indx_list_1 = np.linspace(1, len(xbar_list_1), len(xbar_list_1))\n",
    "    indx_list_2 = np.linspace(1, len(xbar_list_2), len(xbar_list_2))\n",
    "\n",
    "    plt.figure(figsize=(13, 8))\n",
    "    plt.semilogy(indx_list_1, xbar_list_1, label=\"x0 = [-1.2, 1]\");\n",
    "    plt.semilogy(indx_list_2, xbar_list_2, label=\"x0 = [2.8, 4]\");\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log of f(xbar)')\n",
    "    plt.title('Algorithm Convergence')\n",
    "    plt.xticks(np.arange(0,27))\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    return None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_semilogy(xbar_list_1, xbar_list_2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 2\n",
    "###  Experiment with the update rule for the trust region by changing the constants in Algorithm 4.1 in the text Numerical Optimization by Nocedal and Wright 2006. State what you experimented with and discuss your observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### What I notice is that as $\\rho_k$ (rho) decreases, the number of iterations generally increases after a certain value of $\\rho_k$. In this case, after $[0.667, 0.833]$. This means that $\\rho_k$ (rho) and number of iterations are inversely proportional. The reason for this is because updating the trust radius becomes harder as $\\rho_k$ (rho) decreases. I also noticed that $\\rho_k$ must be less than 1 or else the algorithm does not work. It seems that the best number of iterations we get for $x_0 = [-1.2, 1]$ is 23 and 17 for $x_0 = [2.8, 4]$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trust region algorithm \n",
    "def trust_reg_dogleg_test(x0, obj_func, grad, hess, grad_stop_criteria, update, eta=0.15, initial_trust_radius=1, max_trust_radius=300):\n",
    "    xbar_k = x0 # xbar_k = xbar_transposed\n",
    "    trust_reg = initial_trust_radius\n",
    "    k = 1\n",
    "    k_list, xbar_list, obj_func_xbar_list, pbar_list, rho_list, trust_reg_list = [], [], [], [], [], []\n",
    "\n",
    "    while np.linalg.norm(grad(xbar_k)) > grad_stop_criteria:\n",
    "        Bk = hess(xbar_k)\n",
    "        Hk = np.linalg.inv(Bk) # hessian of Bk inverse\n",
    "\n",
    "        # get approx. step pbar_k by dogleg method (gives minimized pbar_k)\n",
    "        pbar_k = dogleg_method(xbar_k, grad, Hk, Bk, trust_reg)\n",
    "\n",
    "        # define a ratio measuring the success of a step\n",
    "        # given a step pbar_k we define the ratio: rho_k = actual reduction / predicted reduction \n",
    "        mk_0 = obj_func(xbar_k)\n",
    "        mk_pbar_k = obj_func(xbar_k) + np.dot(grad(xbar_k),  pbar_k) + 0.5 * np.dot(pbar_k, np.dot(Bk, pbar_k))\n",
    "        act_reduc = obj_func(xbar_k) - obj_func(xbar_k + pbar_k)\n",
    "        pred_reduc = mk_0 - mk_pbar_k\n",
    "        rho_k = act_reduc / pred_reduc\n",
    "\n",
    "        # rho is close to zero or negative, therefore the trust region must shrink\n",
    "        if rho_k < (1 / update):\n",
    "            trust_reg = (1 / update) * trust_reg\n",
    "\n",
    "        # rho is close to one and pbar_k has reached the boundary of the trust region, therefore the trust region must be expanded\n",
    "        # euclidean norm of pbar_k = sqrt(np.dot(pbar_k, pbar_k)) = np.linalg.norm(pbar_k)\n",
    "        else:\n",
    "            if rho_k > ((update - 1) / update) and np.linalg.norm(pbar_k) == trust_reg:\n",
    "                trust_reg = min(2 * trust_reg, max_trust_radius)\n",
    "            else:\n",
    "                trust_reg = trust_reg\n",
    "        \n",
    "        # add to dataframe\n",
    "        if k == 1:\n",
    "            xbar_list.append(x0)\n",
    "            k_list.append(0)\n",
    "            obj_func_xbar_list.append(obj_func(x0))\n",
    "            pbar_list.append(np.nan)\n",
    "            rho_list.append(np.nan)\n",
    "            trust_reg_list.append(np.nan)\n",
    "\n",
    "        # choose position for the next iteration\n",
    "        if rho_k > eta:\n",
    "            xbar_k = xbar_k + pbar_k\n",
    "        else:\n",
    "            xbar_k = xbar_k\n",
    "        \n",
    "        xbar_list.append(xbar_k)\n",
    "        k_list.append(k)\n",
    "        obj_func_xbar_list.append(obj_func(xbar_k))\n",
    "        pbar_list.append(pbar_k)\n",
    "        rho_list.append(rho_k)\n",
    "        trust_reg_list.append(trust_reg)\n",
    "\n",
    "        k = k + 1\n",
    "\n",
    "        trust_reg_dogleg_df = pd.DataFrame(\n",
    "        [[k_list, xbar_list, obj_func_xbar_list, pbar_list, rho_list, trust_reg_list]], \n",
    "        columns=['iteration', 'xbar', 'f(xbar)', 'pbar', 'rho', 'trust_region']\n",
    "    ).explode(['iteration', 'xbar', 'f(xbar)', 'pbar', 'rho', 'trust_region']).reset_index(drop=True)\n",
    "\n",
    "    return trust_reg_dogleg_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vals = [1.2, 1.5, 2, 2.5, 3, 4, 6, 8, 10, 20]\n",
    "for val in vals:\n",
    "    trust_reg_dogleg_test_df = trust_reg_dogleg_test([-1.2, 1], objective_func, gradient, hessian, 10**(-8), val)\n",
    "    print(f\"Initial point: {trust_reg_dogleg_test_df['xbar'].iloc[0]}\")\n",
    "    print(f\"Minimizer using trust region dogleg method (x*): {trust_reg_dogleg_test_df['xbar'].iloc[-1]}\")\n",
    "    print(f\"Value of function at xbar: {objective_func(trust_reg_dogleg_test_df['xbar'].iloc[0])}\")\n",
    "    print(f\"Value of function at x*: {objective_func(trust_reg_dogleg_test_df['xbar'].iloc[-1])}\" )\n",
    "    print(f\"Update constants: {[(1 / val), (val - 1 / val)]}\")\n",
    "    print(f\"Number of iterations: {len(trust_reg_dogleg_test_df['iteration']) - 1}\")\n",
    "    print(\"*\"*65, end=\"\\n\"*2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vals = [1.2, 1.5, 2, 2.5, 3, 4, 6, 8, 10, 20, 50, 100, 300]\n",
    "for val in vals:\n",
    "    trust_reg_dogleg_test_df = trust_reg_dogleg_test([2.8, 4], objective_func, gradient, hessian, 10**(-8), val)\n",
    "    print(f\"Initial point: {trust_reg_dogleg_test_df['xbar'].iloc[0]}\")\n",
    "    print(f\"Minimizer using trust region dogleg method (x*): {trust_reg_dogleg_test_df['xbar'].iloc[-1]}\")\n",
    "    print(f\"Value of function at xbar: {objective_func(trust_reg_dogleg_test_df['xbar'].iloc[0])}\")\n",
    "    print(f\"Value of function at x*: {objective_func(trust_reg_dogleg_test_df['xbar'].iloc[-1])}\" )\n",
    "    print(f\"Update constants: {[(1 / val), (val - 1 / val)]}\")\n",
    "    print(f\"Number of iterations: {len(trust_reg_dogleg_test_df['iteration']) - 1}\")\n",
    "    print(\"*\"*65, end=\"\\n\"*2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resource:\n",
    "- [Example](https://sudonull.com/post/68061-Optimization-method-Trust-Region-DOGLEG-Python-implementation-example)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "fcc29b29288bfae7cd1f9163060093e50b801b38050887fcfbbbb4f16f6170ab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}